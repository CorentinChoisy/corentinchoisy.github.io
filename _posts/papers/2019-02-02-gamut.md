---
layout: paper
categories: papers
permalink: papers/gamut
title: A Design Probe to Understand How Data Scientists Understand Machine Learning Models
---

# Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models
[Fred Hohman][fred], [Andrew Head][andrew], [Rich Caruana][rich], [Rob DeLine][rob], [Steven Drucker][steve]  

<figure>
    <img class="single" src="/images/papers/19-gamut-chi.png">
    <figcaption class="single">
		Interacting with \system's multiple coordinated views together.
		(A) Selecting the OverallQual feature from the sorted Feature Sidebar displays its shape curve in the Shape Curve View.
		(B) Brushing over either explanation for Instance 550 or Instance 798 shows the contribution of the OverallQual feature value for both instances.
		(C) Notice these two houses are similarly predicted $190,606 and $188,620, but for different reasons!

    </figcaption>
</figure>


## Abstract
Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations.
This has led to a rallying cry for model interpretability.
Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. 
Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation.
Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability.
Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness.
Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data.


## Materials
[PDF][19-gamut-chi-pdf] | [Video][19-gamut-chi-Video] | [Preview][19-gamut-chi-preview] | [BibTeX][19-gamut-chi]

## Citation
**[Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models][19-gamut-chi]**  
[Fred Hohman][fred], [Andrew Head][andrew], [Rich Caruana][rich], [Rob DeLine][rob], [Steven Drucker][steve]  
*ACM Conference on Human Factors in Computing Systems (CHI). Glasgow, UK. 2019.*  
<span class="paper-misc">
<span class="cv-website-marker">[Site][19-gamut-chi]</span> | [PDF][19-gamut-chi-pdf] | [Video][19-gamut-chi-Video] | [Preview][19-gamut-chi-preview] | [BibTeX][19-gamut-chi]
</span>

## BibTeX
```
@inproceedings{hohman2019gamut,
  title={Gamut: A Design Probe to Understand How Data Scientists Understand Machine Learning Models},
  author={Hohman, Fred and Head, Andrew and Caruana, Rich and DeLine, Rob and Drucker, Steven M.},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  year={2019},
  organization={ACM}
}
```

[fred]: http://fredhohman.com "Fred Hohman"
[andrew]: http://fredhohman.com "Andrew Head"
[rich]: https://www.microsoft.com/en-us/research/people/rcaruana/ "Rich Caruana"
[rob]: https://www.microsoft.com/en-us/research/people/rdeline/ "Rob DeLine"
[steve]: https://www.microsoft.com/en-us/research/people/sdrucker/ "Steven Drucker"

[19-gamut-chi]: {{ site.url }}/papers/gamut
[19-gamut-chi-pdf]: {{ site.url }}/papers/19-gamut-chi.pdf
[19-gamut-chi-video]: https://youtu.be/R-amW_yNX6I
[19-gamut-chi-preview]: https://youtu.be/7Usb6b3ykPU